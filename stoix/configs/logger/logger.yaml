# --- Logging options ---
# Loggers can be enabled or disabled through the `enable` option. `_target_` specifies the class that is instantiated.
# All other options are specific to the logger.
# Custom loggers can be added by creating a new item in the `loggers` dictionary containing `_target_` and `enabled` keys.

base_exp_path: results/

loggers:
  console:
    _target_: stoix.utils.logger.ConsoleLogger
    enabled: True
  wandb:
    _target_: stoix.utils.logger.WandBLogger
    enabled: False
    # If specified will resume the run with this run ID.
    # This is useful for resuming runs and logging from multiple processes.
    # NOTE: it will overwrite the run unless you set the timestep correctly.
    run_id: ~
    project: ~
    tag: [delete]
    group_tag: [delete]
    detailed_logging: False  # having mean/std/min/max can clutter wandb so we make it optional
    architecture_name: ${arch.architecture_name}  # this is required because async logging causes deadlocks in sebulba
    # Whether JSON file data should be uploaded to WandB for downstream
    # aggregation and plotting of data from multiple experiments. Note that when uploading JSON files,
    # `json.path` must be unset to ensure that uploaded json files don't continue getting larger
    # over time. Setting both will raise an error.
    upload_json_data: False
  neptune:
    _target_: stoix.utils.logger.NeptuneLogger
    enabled: False

    # If specified will resume the run with this run ID.
    # This is useful for resuming runs and logging from multiple processes.
    # NOTE: it will overwrite the run unless you set the timestep correctly.
    run_id: ~
    project: ~
    tag: [delete]
    group_tag: [delete]
    detailed_logging: False  # having mean/std/min/max can clutter neptune so we make it optional
    architecture_name: ${arch.architecture_name}  # this is required because async logging causes deadlocks in sebulba
    # Whether JSON file data should be uploaded to Neptune for downstream
    # aggregation and plotting of data from multiple experiments. Note that when uploading JSON files,
    # `json.path` must be unset to ensure that uploaded json files don't continue getting larger
    # over time. Setting both will raise an error.
    upload_json_data: False
  json:
    _target_: stoix.utils.logger.JsonLogger
    enabled: False

    # If set, json files will be logged to a set path so that multiple experiments can
    # write to the same json file for easy downstream aggregation and plotting with marl-eval.
    path: ~
    task_name: ${env.scenario.task_name}
    env_name: ${env.env_name}
    seed: ${arch.seed}
  tensorboard:
    _target_: stoix.utils.logger.TensorboardLogger
    enabled: False

# --- Checkpointing ---
checkpointing:
  save_model: False # Whether to save model checkpoints.
  save_args:
    save_interval_steps: 1 # Number of steps between saving checkpoints.
    max_to_keep: 1 # Maximum number of checkpoints to keep.
    keep_period: ~ # Don't delete any checkpoint where step % keep_period == 0
    checkpoint_uid: ~ # Unique identifier for checkpoint to save. Defaults to timestamp
    rel_dir: checkpoints # Relative directory to save checkpoints.

  load_model: False # Whether to load model checkpoints.
  load_args:
    checkpoint_uid: "" # Unique identifier for checkpoint to load.
    rel_dir: checkpoints # Relative directory to load checkpoints.
