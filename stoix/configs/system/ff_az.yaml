# --- Defaults FF-AZ ---
# This implementation of AZ is not an exact replica of the original AlphaZero algorithm and serves more as a AlphaZero-like algorithm.
# Additionally, the search method used can be chosen between muzero mcts and gumbel mcts from mctx.

system_name: ff_az # Name of the system.

# --- RL hyperparameters ---
actor_lr: 3e-4 # Learning rate for actor network
critic_lr: 3e-4 # Learning rate for critic network
rollout_length: 16 # Number of environment steps per vectorised environment.
epochs: 8 # Number of epochs per training data batch.
warmup_steps: 16  # Number of steps to collect before training.
total_buffer_size: 50_000 # Total effective size of the replay buffer across all devices and vectorised update steps. This means each device has a buffer of size buffer_size//num_devices which is further divided by the update_batch_size. This value must be divisible by num_devices*update_batch_size.
total_batch_size: 32 # Total effective number of samples to train on. This means each device has a batch size of batch_size/num_devices which is further divided by the update_batch_size. This value must be divisible by num_devices*update_batch_size.
sample_sequence_length: 16 # Number of steps to consider for each element of the batch.
period : 1 # Period of the sampled sequences.
gamma: 0.99 # Discounting factor.
gae_lambda: 0.95 # Lambda value for GAE computation.
ent_coef: 0.0 # Entropy regularisation term for loss function.
vf_coef: 1.0 # Critic weight in
max_grad_norm: 0.5 # Maximum norm of the gradients for a weight update.
decay_learning_rates: False # Whether learning rates should be linearly decayed during training.
num_simulations: 25 # Number of simulations to run.
max_depth: ~ # Maximum depth of the search tree.
search_method : muzero # Search method to use. Options: gumbel, muzero.
search_method_kwargs: {} # Additional kwargs for the search method.
